# ğŸ¤–âš™ï¸ RoboVisionSmith ğŸš€
Robotics Vision Research project developed under Prof. Joseph Vybihal at McGill Artificial Intelligence and Robotics Research Laboratory. Focused on non-neural robotic vision for classifying environments on Research Labâ€™s NavigBot-Compact (IMX477 12MP) and TerrainScout-Micro (OV9281 global shutter) platforms, optimized for resource-constrained embedded systems.


## ğŸ“„ Full Lab Research Report

For complete methodology, results, accuracy breakdowns, and classifier insights:  
ğŸ‘‰ **[Download the Final Research Lab Report (PDF)](https://github.com/ShahmeerSajid/RoboVisionSmith/blob/main/Research%20Report/%22Enhancing%20Robot%20Vision%20â€“%20Beyond%20Principal%20Component%20Analysis%20(PCA)%20for%20Intelligent%20Environmental%20Understanding%22%20--%20final.pdf)**  
(Located inside the `Research Report` folder)


The Report Includes:

- ğŸ“Š Detailed breakdown of feature engineering & pipeline architecture
- ğŸ§ª Performance analysis of individual classifiers on 700+ real-world images captured across McGill    campus and surrounding vicinity environments
- ğŸ“· Visual outputs and interpretability aids â€” including edge maps, scene graphs, classification charts, and performance gauges
- ğŸ§  Numerical values for 230+ global features, extracted from raw, live-captured robotic vision data ready for analysis or replication


## ğŸ”® Future Work
This research project achieved approximately 68% classification accuracy on live-captured environmental data using the engineered classification pipeline. Moving forward, the project will be extended by future students and members of McGill AI and Robotics Lab, who will build upon the robotic vision software foundation established in this work.

# 🤖⚙️ RoboVisionSmith 🚀
Robotics Vision Research project developed under Prof. Joseph Vybihal at McGill Artificial Intelligence and Robotics Research Laboratory. Focused on non-neural robotic vision for classifying environments on Research Lab’s NavigBot-Compact (IMX477 12MP) and TerrainScout-Micro (OV9281 global shutter) platforms, optimized for resource-constrained embedded systems.


## 📄 Full Lab Research Report

For complete methodology, results, accuracy breakdowns, and classifier insights:  
👉 **[Download the Final Research Lab Report (PDF)](https://github.com/ShahmeerSajid/RoboVisionSmith/blob/main/Research%20Report/%22Enhancing%20Robot%20Vision%20–%20Beyond%20Principal%20Component%20Analysis%20(PCA)%20for%20Intelligent%20Environmental%20Understanding%22%20--%20final.pdf)**  
(Located inside the `Research Report` folder)


The Report Includes:

- 📊 Detailed breakdown of feature engineering & pipeline architecture
- 🧪 Performance analysis of individual classifiers on 700+ real-world images captured across McGill    campus and surrounding vicinity environments
- 📷 Visual outputs and interpretability aids — including edge maps, scene graphs, classification       charts, and performance gauges
- 🧠 Numerical values for 230+ global features, extracted from raw, live-captured robotic vision data   ready for analysis or replication


## 🔮 Future Work
This project lays the groundwork for a lightweight robotic vision system capable of classifying environments using interpretable logic. My primary focus was on developing the software pipeline — from feature engineering and dataset generation to classifier evaluation.
🧠 The next stage of this research will be carried forward by future students and collaborators at the Robotics Vision Lab, who will focus on deploying the software onto the two physical robot platforms.
